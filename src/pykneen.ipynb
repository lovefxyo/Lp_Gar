{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "e_data=pd.read_csv(\"./graph_dataset/dblp_1980/dblp_e.csv\")\n",
    "e_data.iloc[:,1:].to_csv(\"./graph_dataset/dblp_1980/dblp_e_pykneen.tsv\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PurePath.__fspath__ of PosixPath('/Users/pygmalion/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/datasets/nations/train.txt')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets.nations import NATIONS_TRAIN_PATH\n",
    "tf = TriplesFactory.from_path(\"./graph_dataset/dblp_1980/dblp_e_pykneen.tsv\")\n",
    "NATIONS_TRAIN_PATH.__fspath__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=3351857418\n",
      "No random seed is specified. Setting to 1183159944.\n",
      "No cuda devices were available. The model runs on CPU\n",
      "Training epochs on cpu:   0%|          | 0/5 [00:16<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pygmalion/Desktop/毕业设计/实验/数据处理代码/pykneen.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=0'>1</a>\u001b[0m training, testing \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msplit()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=2'>3</a>\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=3'>4</a>\u001b[0m     testing\u001b[39m=\u001b[39;49mtesting,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=4'>5</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTransE\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,  \u001b[39m# short epochs for testing - you should go higher\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pygmalion/Desktop/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E5%AE%9E%E9%AA%8C/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81/pykneen.ipynb#ch0000001?line=7'>8</a>\u001b[0m result\u001b[39m.\u001b[39msave_to_directory(\u001b[39m\"\u001b[39m\u001b[39m./graph_dataset/dblp_1980/pykneen/test\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py:1200\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1197'>1198</a>\u001b[0m \u001b[39m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1198'>1199</a>\u001b[0m training_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1199'>1200</a>\u001b[0m losses \u001b[39m=\u001b[39m training_loop_instance\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1200'>1201</a>\u001b[0m     triples_factory\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1201'>1202</a>\u001b[0m     stopper\u001b[39m=\u001b[39;49mstopper_instance,\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1202'>1203</a>\u001b[0m     result_tracker\u001b[39m=\u001b[39;49m_result_tracker,\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1203'>1204</a>\u001b[0m     clear_optimizer\u001b[39m=\u001b[39;49mclear_optimizer,\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1204'>1205</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtraining_kwargs,\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1205'>1206</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1206'>1207</a>\u001b[0m \u001b[39massert\u001b[39;00m losses \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/pipeline/api.py?line=1207'>1208</a>\u001b[0m training_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py:329\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=326'>327</a>\u001b[0m     result: Optional[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses_per_epochs\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=327'>328</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=328'>329</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=329'>330</a>\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=330'>331</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=331'>332</a>\u001b[0m         slice_size\u001b[39m=\u001b[39;49mslice_size,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=332'>333</a>\u001b[0m         label_smoothing\u001b[39m=\u001b[39;49mlabel_smoothing,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=333'>334</a>\u001b[0m         sampler\u001b[39m=\u001b[39;49msampler,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=334'>335</a>\u001b[0m         continue_training\u001b[39m=\u001b[39;49mcontinue_training,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=335'>336</a>\u001b[0m         only_size_probing\u001b[39m=\u001b[39;49monly_size_probing,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=336'>337</a>\u001b[0m         use_tqdm\u001b[39m=\u001b[39;49muse_tqdm,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=337'>338</a>\u001b[0m         use_tqdm_batch\u001b[39m=\u001b[39;49muse_tqdm_batch,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=338'>339</a>\u001b[0m         tqdm_kwargs\u001b[39m=\u001b[39;49mtqdm_kwargs,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=339'>340</a>\u001b[0m         stopper\u001b[39m=\u001b[39;49mstopper,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=340'>341</a>\u001b[0m         result_tracker\u001b[39m=\u001b[39;49mresult_tracker,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=341'>342</a>\u001b[0m         sub_batch_size\u001b[39m=\u001b[39;49msub_batch_size,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=342'>343</a>\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=343'>344</a>\u001b[0m         save_checkpoints\u001b[39m=\u001b[39;49msave_checkpoints,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=344'>345</a>\u001b[0m         checkpoint_path\u001b[39m=\u001b[39;49mcheckpoint_path,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=345'>346</a>\u001b[0m         checkpoint_frequency\u001b[39m=\u001b[39;49mcheckpoint_frequency,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=346'>347</a>\u001b[0m         checkpoint_on_failure_file_path\u001b[39m=\u001b[39;49mcheckpoint_on_failure_file_path,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=347'>348</a>\u001b[0m         best_epoch_model_file_path\u001b[39m=\u001b[39;49mbest_epoch_model_file_path,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=348'>349</a>\u001b[0m         last_best_epoch\u001b[39m=\u001b[39;49mlast_best_epoch,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=349'>350</a>\u001b[0m         drop_last\u001b[39m=\u001b[39;49mdrop_last,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=350'>351</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=351'>352</a>\u001b[0m         gradient_clipping_max_norm\u001b[39m=\u001b[39;49mgradient_clipping_max_norm,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=352'>353</a>\u001b[0m         gradient_clipping_norm_type\u001b[39m=\u001b[39;49mgradient_clipping_norm_type,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=353'>354</a>\u001b[0m         gradient_clipping_max_abs_value\u001b[39m=\u001b[39;49mgradient_clipping_max_abs_value,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=354'>355</a>\u001b[0m         triples_factory\u001b[39m=\u001b[39;49mtriples_factory,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=355'>356</a>\u001b[0m         training_instances\u001b[39m=\u001b[39;49mtraining_instances,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=356'>357</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=358'>359</a>\u001b[0m \u001b[39m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=359'>360</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py:606\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, training_instances, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=602'>603</a>\u001b[0m stop \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start \u001b[39m+\u001b[39m _sub_batch_size, current_batch_size)\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=604'>605</a>\u001b[0m \u001b[39m# forward pass call\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=605'>606</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=606'>607</a>\u001b[0m     batch,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=607'>608</a>\u001b[0m     start,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=608'>609</a>\u001b[0m     stop,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=609'>610</a>\u001b[0m     current_batch_size,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=610'>611</a>\u001b[0m     label_smoothing,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=611'>612</a>\u001b[0m     slice_size,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=612'>613</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=613'>614</a>\u001b[0m current_epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=614'>615</a>\u001b[0m callback\u001b[39m.\u001b[39mon_batch(epoch\u001b[39m=\u001b[39mepoch, batch\u001b[39m=\u001b[39mbatch, batch_loss\u001b[39m=\u001b[39mbatch_loss)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py:781\u001b[0m, in \u001b[0;36mTrainingLoop._forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=777'>778</a>\u001b[0m     loss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m this_sub_batch_size \u001b[39m/\u001b[39m current_batch_size\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=779'>780</a>\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=780'>781</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=781'>782</a>\u001b[0m current_epoch_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/pykeen/training/training_loop.py?line=783'>784</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpost_forward_pass()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training, testing = tf.split()\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    model='TransE',\n",
    "    epochs=5,  # short epochs for testing - you should go higher\n",
    ")\n",
    "result.save_to_directory(\"./graph_dataset/dblp_1980/\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7eecec397c16758716d6d2477f82ea485c5fb1c0dda44cf73447b23f0e41c9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
